{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "step_size = 0.0001\n",
    "penalty = 'l2'\n",
    "eps = 10**-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File output/random_test0314.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1c24515073e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/random_test0314.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/random_train0314.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/random_val0314.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File output/random_test0314.csv does not exist"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train = pd.read_csv(\"output/random_test0314.csv\")\n",
    "test = pd.read_csv(\"output/random_train0314.csv\")\n",
    "val = pd.read_csv(\"output/random_val0314.csv\")\n",
    "\n",
    "print len(train.columns), \"columns\"\n",
    "print train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = float(len(train))\n",
    "m_test = float(len(test))\n",
    "m_val = float(len(val))\n",
    "print m_train, m_test, m_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some statistics\n",
    "print 'Train set:'\n",
    "chargeoff_count = (train.LoanStatus == \"CHGOFF\").sum()\n",
    "print 'Chargeoffs:', chargeoff_count\n",
    "print 'Percentage of loans that defaulted:', float(chargeoff_count)/m_train\n",
    "\n",
    "print '\\n', 'Test set:'\n",
    "chargeoff_count = (test.LoanStatus == \"CHGOFF\").sum()\n",
    "print 'Chargeoffs:', chargeoff_count\n",
    "print 'Percentage of loans that defaulted:', float(chargeoff_count)/m_test\n",
    "\n",
    "print '\\n', 'Validation set:'\n",
    "chargeoff_count = (val.LoanStatus == \"CHGOFF\").sum()\n",
    "print 'Chargeoffs:', chargeoff_count\n",
    "print 'Percentage of loans that defaulted:', float(chargeoff_count)/m_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove variables we don't want\n",
    "c = train.columns.tolist()\n",
    "dropped_columns = ['LoanStatus', 'ChargeOffDate', 'GrossChargeOffAmount', 'BorrZip', 'CDC_Zip', 'BorrCity',\n",
    "                   'CDC_City', 'ThirdPartyLender_City', 'ProjectCounty', 'ApprovalDate', 'GrossApproval']\n",
    "for col in dropped_columns:\n",
    "    c.remove(col)\n",
    "print(len(c)), \"covariates\"\n",
    "print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate data into covariates and targets\n",
    "x_train = train[c]\n",
    "x_test = test[c]\n",
    "x_val = val[c]\n",
    "\n",
    "y_train = (train['LoanStatus'].values == \"CHGOFF\")*1\n",
    "y_test = (test['LoanStatus'].values == \"CHGOFF\")*1\n",
    "y_val = (val['LoanStatus'].values == \"CHGOFF\")*1\n",
    "\n",
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print x_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate how many covariates we add by the expanding categorical columns\n",
    "numerics = x_train.select_dtypes(include=[np.number,'bool'])\n",
    "cats = x_train.drop(columns=numerics.columns)\n",
    "\n",
    "uniques = np.unique(cats.values)\n",
    "\n",
    "print \"approx. number of covariate levels:\", len(uniques)\n",
    "print cats.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical variables to dummy variables\n",
    "x_train = pd.get_dummies(x_train)\n",
    "x_test = pd.get_dummies(x_test)\n",
    "x_val = pd.get_dummies(x_val)\n",
    "\n",
    "print x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the data sets all have the same levels\n",
    "def add_missing_columns(d1, d2):\n",
    "    missing_cols_2 = (set(d1.columns) - set(d2.columns))\n",
    "    missing_cols_1 = (set(d2.columns) - set(d1.columns))\n",
    "    for c in missing_cols_2:\n",
    "        d2[c] = 0\n",
    "    for c in missing_cols_1:\n",
    "        d1[c] = 0\n",
    "    return d1, d2\n",
    "\n",
    "print 'before fixing columns: '\n",
    "print x_train.shape\n",
    "print x_test.shape\n",
    "print x_val.shape\n",
    "\n",
    "x_train, x_test = add_missing_columns(x_train, x_test)\n",
    "x_train, x_val = add_missing_columns(x_train, x_val)\n",
    "x_test, x_val = add_missing_columns(x_test, x_val)\n",
    "print 'after fixing columns: '\n",
    "print x_train.shape\n",
    "print x_test.shape\n",
    "print x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best regularization factor and stopping time\n",
    "def lr_model(x, y, C = 1, penalty = 'l2', tol = 10**-4):\n",
    "    lr = LogisticRegression(solver='liblinear', multi_class= 'ovr', C=C,\n",
    "                        penalty = penalty, fit_intercept=True, max_iter=200, tol = tol)\n",
    "    lr.fit(x, y)\n",
    "    return lr\n",
    "\n",
    "def calc_auc(x, y, C = 1, penalty = 'l2', tol = 10**-4):\n",
    "    lr = lr_model(x, y, C = C, penalty = penalty, tol = tol)\n",
    "    \n",
    "    y_probs_val = lr.predict_proba(x_val)\n",
    "    val_fprs, val_tprs  = [], [] \n",
    "    for threshold in np.arange(step_size,1,step_size):\n",
    "        y_preds_val = y_probs_val[:,1] > threshold\n",
    "        val_fprs.append(np.sum((y_val == 0) * (y_preds_val == 1)) / (np.sum(y_val == 0, dtype=float) + eps))\n",
    "        val_tprs.append(np.sum((y_val == 1) * (y_preds_val == 1)) / (np.sum(y_val == 1, dtype=float) + eps))\n",
    "\n",
    "    x_prev = 0.\n",
    "    auc = 0\n",
    "    for x, y in zip(sorted(val_fprs), sorted(val_tprs)):\n",
    "        auc += (x - x_prev)*y\n",
    "        x_prev = x\n",
    "    return auc\n",
    "\n",
    "C_range = [2**i for i in range(-5,5)]\n",
    "tol_range = [10**i for i in range(-8, -1)]\n",
    "auc_results = {}\n",
    "for C in C_range:\n",
    "    for tol in tol_range:\n",
    "        auc_results[calc_auc(x_train, y_train, C = C, tol = tol)] = (C, tol)\n",
    "opt_auc = np.max(auc_results.keys())\n",
    "opt_setting = auc_results[opt_auc]\n",
    "\n",
    "print opt_setting, \":\", opt_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot AUC curves\n",
    "auc_C_avg = np.zeros(len(C_range))\n",
    "auc_tol_avg = np.zeros(len(tol_range))\n",
    "for auc, (C, tol) in auc_results.items():\n",
    "    auc_C_avg[C_range.index(C)] += auc\n",
    "    auc_tol_avg[tol_range.index(tol)] += auc\n",
    "auc_C_avg = auc_C_avg / len(tol_range)\n",
    "auc_tol_avg = auc_tol_avg / len(C_range)\n",
    "\n",
    "plt.xscale('log', basex = 2)\n",
    "plt.plot(C_range, auc_C_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xscale('log', basex = 10)\n",
    "plt.plot(tol_range, auc_tol_avg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model and generate outputs\n",
    "C_opt, tol_opt = opt_setting\n",
    "lr = lr_model(x_train, y_train, C = C_opt, penalty = penalty, tol = tol_opt)\n",
    "\n",
    "y_probs_train = lr.predict_proba(x_train)\n",
    "y_probs_val = lr.predict_proba(x_val)\n",
    "print y_probs_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate some statistics\n",
    "y_preds_val = y_probs_val[:,1] > 0.2\n",
    "print y_preds_val[:5].reshape(5,1)\n",
    "print \"\\n\", \"validation accuracy\", np.sum(y_preds_val == y_val, dtype=float) / m_val\n",
    "print \"false positive rate\",  np.sum((y_val == 0) * (y_preds_val == 1)) / (np.sum(y_val == 0, dtype=float) + eps)\n",
    "print \"true positive rate\", np.sum((y_val == 1) * (y_preds_val == 1)) / (np.sum(y_val == 1, dtype=float) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ROC curve\n",
    "train_fprs, train_tprs, val_fprs, val_tprs  = [], [], [], []\n",
    "for threshold in np.arange(step_size,1,step_size):\n",
    "    y_preds_val = y_probs_val[:,1] > threshold\n",
    "    val_fprs.append(np.sum((y_val == 0) * (y_preds_val == 1)) / (np.sum(y_val == 0) + eps))\n",
    "    val_tprs.append(np.sum((y_val == 1) * (y_preds_val == 1)) / (np.sum(y_val == 1) + eps))\n",
    "    \n",
    "    y_preds_train = y_probs_train[:,1] > threshold\n",
    "    train_fprs.append(np.sum((y_train == 0) * (y_preds_train == 1)) / (np.sum(y_train == 0) + eps))\n",
    "    train_tprs.append(np.sum((y_train == 1) * (y_preds_train == 1)) / (np.sum(y_train == 1) + eps))\n",
    "print val_fprs[:5]\n",
    "print val_tprs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "plt.title(\"ROC Curve for Logistic Regression\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.xlabel(\"false positive rate\")\n",
    "\n",
    "valplt, = plt.plot(val_fprs,val_tprs,label='validation')\n",
    "trainplt, = plt.plot(train_fprs,train_tprs,label='train')\n",
    "plt.legend(handles = [valplt, trainplt])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = 0\n",
    "x_prev = 0\n",
    "for x, y in zip(sorted(val_fprs), sorted(val_tprs)):\n",
    "    auc += (x - x_prev)*y\n",
    "    x_prev = x\n",
    "print auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ROC curve\n",
    "with open(\"logistic_roc.csv\", \"w\") as file:\n",
    "    file.write(\"threshold,fpr,tpr\\n\")\n",
    "    for i, (fpr, tpr) in enumerate(zip(val_fprs, val_tprs), 1):\n",
    "        file.write(str(step_size + i) + \",\" + str(fpr) + \",\" + str(tpr) + \"\\n\")\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best threshold\n",
    "senses = np.array(val_tprs, dtype=float) + eps\n",
    "specs = 1 - np.array(val_fprs, dtype=float) + eps\n",
    "h_mean = 2. / (1 / senses + 1 / specs)\n",
    "opt_index = np.argmax(h_mean)\n",
    "opt_threshold = opt_index*step_size\n",
    "\n",
    "print \"best threshold: \" , opt_threshold\n",
    "print \"highest sensitivity: \", val_tprs[opt_index]\n",
    "print \"highest specificity: \", 1 - val_fprs[opt_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_probs_train = lr.predict_proba(x_train)[:,1]\n",
    "y_preds_train = y_probs_train > opt_threshold\n",
    "\n",
    "y_probs_test = lr.predict_proba(x_test)[:,1]\n",
    "y_preds_test = y_probs_test > opt_threshold\n",
    "\n",
    "print y_probs_test[:5]\n",
    "print y_preds_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit on training data to see if there is underfitting\n",
    "print 'Training set'\n",
    "print 'predicted proportion of defaults: ', np.sum(y_preds_train == 1) / m_train\n",
    "print 'accuracy: ', np.sum(y_preds_train == y_train) / m_train\n",
    "\n",
    "# fit on test set to see if there is overfitting\n",
    "print '\\nTest set'\n",
    "print 'predicted proportion of defaults: ', np.sum(y_preds_test == 1) / m_test\n",
    "print 'accuracy: ', np.sum(y_preds_test == y_test) / m_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate F1 score\n",
    "precision = np.sum((y_test == 1) * (y_preds_test == 1)) / (np.sum(y_preds_test == 1) + eps)\n",
    "recall = np.sum((y_test == 1) * (y_preds_test == 1)) / (np.sum(y_test == 1) + eps)\n",
    "F1 = 2/(1 / (precision + eps) + 1 / (recall + eps))\n",
    "print \"precision: \", round(precision,6), \"\\trecall:\", round(recall,6), \"\\tF1 score:\", round(F1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood estimation\n",
    "def log_likelihood(probs, y):\n",
    "    return np.sum(np.log(probs[y*1]))\n",
    "\n",
    "full_ll = log_likelihood(y_probs_train, y_train)\n",
    "\n",
    "ll_ratio_test = []\n",
    "for column in x_train.columns:\n",
    "    x_temp = x_train.copy()\n",
    "    x_temp[column] = 0\n",
    "    y_probs_temp = lr.predict_proba(x_temp)\n",
    "    temp_ll = log_likelihood(y_probs_temp, y_train)\n",
    "    ll_ratio_test.append((column,2*(full_ll - temp_ll)))\n",
    "\n",
    "ll_ratio_test = sorted(ll_ratio_test, key=lambda t: (-t[1], t[0]))\n",
    "\n",
    "for i in range(5):\n",
    "    print ll_ratio_test[i]\n",
    "print \"\"\n",
    "for i in range(-5,0):\n",
    "    print ll_ratio_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to discuss/redo cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "\n",
    "# print 'Training set'\n",
    "# print metrics.classification_report(y_train, y_pred_train)\n",
    "# print '\\nTest set'\n",
    "# print metrics.classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### optional ##########\n",
    "# # if import from sorted data - need to downsample train dataset to be more balanced\n",
    "# # can call the following function multiple times for decreasing in log term\n",
    "# # dropping PIF samples with 50% probability\n",
    "\n",
    "# def drop_half(train):\n",
    "#     print 'before drop: ', train.shape[0]\n",
    "#     dropidx = []\n",
    "#     for idx, val in train['LoanStatus'].iteritems():\n",
    "#         if val != 'CHGOFF':\n",
    "#             rand = np.random.rand()\n",
    "#             if rand < 0.5:\n",
    "#                 dropidx.append(idx)\n",
    "#     train = train.drop(dropidx)\n",
    "#     print 'after drop: ', train.shape[0]\n",
    "#     return train\n",
    "    \n",
    "# train = drop_half(train)\n",
    "# train = drop_half(train)\n",
    "# # test = drop_half(test)\n",
    "\n",
    "# chargeoff_count = (train['LoanStatus'] == \"CHGOFF\").sum()\n",
    "# print 'Chargeoffs:', chargeoff_count\n",
    "# print 'Percentage of loans that defaulted:', float(chargeoff_count)/len(train)\n",
    "\n",
    "# chargeoff_count = (test['LoanStatus'] == \"CHGOFF\").sum()\n",
    "# print 'Chargeoffs:', chargeoff_count\n",
    "# print 'Percentage of loans that defaulted:', float(chargeoff_count)/len(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
