{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seed for any random operations\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test points: 5481\n"
     ]
    }
   ],
   "source": [
    "# Read in test dataset (TODO: test data being used is temporary. replace with final test data.)\n",
    "train_data = pd.read_csv(\"sorted_hazard_train0314.csv\")\n",
    "test_data = pd.read_csv(\"sorted_hazard_test0314.csv\")\n",
    "print \"Number of test points:\", test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the usual filtering and matching to train data\n",
    "c = train.columns.tolist()\n",
    "c.remove('LoanStatus')\n",
    "c.remove('ChargeOffDate')\n",
    "c.remove('GrossChargeOffAmount')\n",
    "c.remove('BorrZip')\n",
    "c.remove('CDC_Zip')\n",
    "c.remove('BorrCity')\n",
    "\n",
    "c.remove('BorrState')\n",
    "c.remove('CDC_State')\n",
    "c.remove('ThirdPartyLender_State')\n",
    "c.remove('ProjectState')\n",
    "\n",
    "c.remove('CDC_City')\n",
    "c.remove('ProjectCounty')\n",
    "c.remove('ThirdPartyLender_City')\n",
    "c.remove('ApprovalDate')\n",
    "\n",
    "print c\n",
    "\n",
    "x_train = train[c]\n",
    "print x_train.columns.tolist()\n",
    "x_train = pd.get_dummies(x_train).astype(float)\n",
    "print x_train.shape\n",
    "\n",
    "x_test = test[c]\n",
    "print x_test.columns.tolist()\n",
    "x_test = pd.get_dummies(x_test).astype(float)\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to get consistent feature dimensions for both train and test dataset\n",
    "def add_missing_dummy_columns(d1, d2):\n",
    "    missing_cols = set(d1.columns) - set(d2.columns)\n",
    "    for c in missing_cols:\n",
    "        d2[c] = 0\n",
    "    return d2\n",
    "\n",
    "print 'before fix columns: '\n",
    "print x_train.shape\n",
    "print x_test.shape\n",
    "\n",
    "def fix_columns(x_train, x_test):  \n",
    "\n",
    "    x_test = add_missing_dummy_columns(x_train, x_test)\n",
    "\n",
    "    extra_cols = set(x_test.columns) - set(x_train.columns)\n",
    "    x_test = x_test[x_train.columns]\n",
    "    return x_test\n",
    "\n",
    "x_test = fix_columns(x_train, x_test)\n",
    "print 'after fix columns: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out certain attributes from a loan covariate for loss model\n",
    "def filter_loan(loan):  \n",
    "    after_loss = loan.columns.tolist()\n",
    "    after_loss.remove('GrossApproval')\n",
    "    after_loss.remove('Log_GrossApproval_Norm')\n",
    "    after_loss.remove('Default?')\n",
    "    return loan[after_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of simulations we want\n",
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-aa393f9270e9>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-aa393f9270e9>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    default_prob = # hand-calculate\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Predicts if loan is defaulted by time t in years\n",
    "def is_defaulted_by(loan, years):\n",
    "    # GIVEN LAMBDA\n",
    "    default_prob = # Hand-calculate or calculate from hazard model\n",
    "    u = np.random.uniform(0, 1)\n",
    "    return (u <= default_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculates loss of a loan using loss distribution model,\n",
    "# assuming model is stored in loss_model\n",
    "def calculate_loss(loan):\n",
    "    gross_approval = loan['GrossApproval']\n",
    "    filtered_loan = filter_loan(loan)\n",
    "    pred = max(0, loss_model.predict(filtered_loan))\n",
    "    return pred * gross_approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulates total loss of 500 loans for a t year horizon\n",
    "def simulate_total_loss(N, years):\n",
    "    total_losses = []\n",
    "    total_loan_amounts = []\n",
    "    for n in range(0, N):\n",
    "        sampled_loans = test_data.sample(500)\n",
    "        cur_loss = 0.0\n",
    "        \n",
    "        for i in range(0, 500):\n",
    "            cur_loan = sampled_loans[i:i+1]\n",
    "            if is_defaulted_by(cur_loan, years=1):\n",
    "                loan_loss = calculate_loss(cur_loan)\n",
    "                cur_loss += loan_loss\n",
    "        \n",
    "        total_losses.append(cur_loss)\n",
    "        total_loan_amounts.append(sampled_loans['GrossApproval'].sum())\n",
    "    \n",
    "    return total_losses, total_loan_amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# QUESTION: Should we remove samples where no loans have defaulted? Are we focused on \n",
    "# only loan pools that have defaults or all loan pools in general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimate for 1 year and plot histogram\n",
    "total_1_year_losses, total_1_year_loan_amounts = simulate_total_loss(N, 1)\n",
    "sns.distplot(total_1_year_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat for 5 year and plot histogram\n",
    "total_5_year_losses, total_5_year_loan_amounts = simulate_total_loss(N, 5)\n",
    "sns.distplot(total_5_year_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate VaR of sorted list of values\n",
    "def get_VAR(sorted_losses, level):\n",
    "    index = int((1-level) * 500)\n",
    "    return sorted_losses[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Average VaR of sorted list of values\n",
    "def get_avg_VAR(sorted_losses, level):\n",
    "    index = int((1-level) * 500)\n",
    "    return np.mean(sorted_losses[:index+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate confidence interval\n",
    "def get_conf_interval(sample, level=0.95):\n",
    "    n, min_max, mean, var, skew, kurt = stats.describe(sample)\n",
    "    std = math.sqrt(var)\n",
    "    return stats.norm.interval(level, loc=mean, scale=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bootstrap to calculate VaR and Average VaR with confidence intervals\n",
    "def bootstrap_vars(N, total_losses, level=0.95):\n",
    "    losses_df = pd.Series(total_losses)\n",
    "    VaR_samples = []\n",
    "    AVaR_samples = []\n",
    "    \n",
    "    for i in range(0, N):\n",
    "        bootstrap_sample = sorted(losses_df.sample(500, replace=True).tolist())\n",
    "        VaR = get_VAR(bootstrap_sample, level)\n",
    "        AVaR = get_avg_VAR(bootstrap_sample, level)\n",
    "        VaR_samples.append(VaR)\n",
    "        AVaR_samples.append(AVaR)\n",
    "    \n",
    "    print \"VaR estimate (mean):\", np.mean(VaR_samples)\n",
    "    print \"Average VaR estimate (mean):\", np.mean(AVaR_samples)\n",
    "    print \"VaR confidence interval:\", get_conf_interval(VaR_samples, level)\n",
    "    print \"AVaR confidence interval:\", get_conf_interval(AVaR_samples, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of bootstrap simulations\n",
    "B = 1000\n",
    "\n",
    "# Print results\n",
    "print \"1-year loss at 95% level:\"\n",
    "bootstrap_vars(B, total_1_year_losses, 0.95)\n",
    "print \"\"\n",
    "print \"1-year loss at 99% level:\"\n",
    "bootstrap_vars(B, total_1_year_losses, 0.99)\n",
    "print \"\"\n",
    "print \"5-year loss at 95% level:\"\n",
    "bootstrap_vars(B, total_5_year_losses, 0.95)\n",
    "print \"\"\n",
    "print \"5-year loss at 99% level:\"\n",
    "bootstrap_vars(B, total_5_year_losses, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find junior [5%, 15%] and senior tranches [15%, 100%] for 1 year\n",
    "junior_tranche = []\n",
    "senior_tranche = []\n",
    "\n",
    "for i in range(0, N):\n",
    "    loan_amount = total_1_year_loan_amounts[i]\n",
    "    loss_amount = total_1_year_losses[i]\n",
    "    \n",
    "    loss_percentage = float(loss_amount) / loan_amount\n",
    "    junior_loss_percentage = 0.0\n",
    "    senior_loss_percentage = 0.0\n",
    "    \n",
    "    # Loss for junior tranche\n",
    "    if loss_percentage >= 0.05:\n",
    "        if loss_percentage >= 0.15:\n",
    "            junior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            junior_loss_percentage = (loss_percentage - 0.05) / (0.15 - 0.05)\n",
    "    \n",
    "    # Loss for senior tranche\n",
    "    if loss_percentage >= 0.15:\n",
    "        if loss_percentage >= 1.0:\n",
    "            senior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            senior_loss_percentage = (loss_percentage - 0.15) / (1.0 - 0.15)\n",
    "        \n",
    "    junior_tranche.append(junior_loss_percentage)\n",
    "    senior_tranche.append(senior_loss_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot junior histogram\n",
    "j = sns.distplot(junior_tranche)\n",
    "sns.despine()\n",
    "j.axes.set_title('Junior Tranche', fontsize=20, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot senior histogram\n",
    "s = sns.distplot(senior_tranche)\n",
    "sns.despine()\n",
    "s.axes.set_title('Senior Tranche', fontsize=20, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeat for 5 year\n",
    "junior_tranche = []\n",
    "senior_tranche = []\n",
    "\n",
    "for i in range(0, N):\n",
    "    loan_amount = total_5_year_loan_amounts[i]\n",
    "    loss_amount = total_5_year_losses[i]\n",
    "    \n",
    "    loss_percentage = float(loss_amount) / loan_amount\n",
    "    junior_loss_percentage = 0.0\n",
    "    senior_loss_percentage = 0.0\n",
    "    \n",
    "    # Loss for junior tranche\n",
    "    if loss_percentage >= 0.05:\n",
    "        if loss_percentage >= 0.15:\n",
    "            junior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            junior_loss_percentage = (loss_percentage - 0.05) / (0.15 - 0.05)\n",
    "    \n",
    "    # Loss for senior tranche\n",
    "    if loss_percentage >= 0.15:\n",
    "        if loss_percentage >= 1.0:\n",
    "            senior_loss_percentage = 1.0  # Lost it all\n",
    "        else:\n",
    "            senior_loss_percentage = (loss_percentage - 0.15) / (1.0 - 0.15)\n",
    "        \n",
    "    junior_tranche.append(junior_loss_percentage)\n",
    "    senior_tranche.append(senior_loss_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot junior histogram\n",
    "j = sns.distplot(junior_tranche)\n",
    "sns.despine()\n",
    "j.axes.set_title('Junior Tranche', fontsize=20, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot senior histogram\n",
    "s = sns.distplot(senior_tranche)\n",
    "sns.despine()\n",
    "s.axes.set_title('Senior Tranche', fontsize=20, alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [anaconda2]",
   "language": "python",
   "name": "Python [anaconda2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
